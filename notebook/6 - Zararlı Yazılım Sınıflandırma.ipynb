{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AB2017 - Python ile Pratik Makine Öğrenimi\n",
    "\n",
    "Bu dökümanda çok basit düzeyde zararlı yazılım sınıflandırması yapan bir sistem eğiteceğiz. Örneğin orjinalini [şu adreste](https://www.youtube.com/watch?v=iLNHVwSu9EA&t=2s) bulabilirsiniz. Gerekli bazı importları yaparak başlıyoruz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import ensemble\n",
    "from sklearn import model_selection, tree, linear_model\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sistem için gerekli verileri dosyadan yüklüyoruz. Zararlı yazılım örnekleri için isim ve bütünlük koduna ihtiyacımız olmadığından **Name** ve **md5** sütunlarını almıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/data.csv\", sep=\"|\")\n",
    "X = data.drop([\"Name\", \"md5\", \"legitimate\"], axis=1).values\n",
    "y = data['legitimate'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Başlamadan önce öznitelikler üstünde dönüşüm işlemi yapıyoruz. Bunun için ayrıca bir sınıflandırıcı model gerekiyor. Ardından tipik **train_test_split** metodu ile %30 test için olacak şekilde verisetini bölümlüyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_selector = ensemble.ExtraTreesClassifier().fit(X, y)\n",
    "model = SelectFromModel(feature_selector, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "feature_count = X_new.shape[1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_new, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bir önceki örneklerden farklı olarak bu sefer birden fazla modeli ve parametre kombinasyonlarını deneyeceğiz. Bunun için yapılabilecek en basit şey anahtar elemanı model, değeri parametre sözlüğü olan bir sözlük oluşturmak. Buradan elde ettiğimiz model ve sonuçları ise **model_results** adlı sözlükte tutacağız.\n",
    "\n",
    "**UYARI:** Bu işlem bilgisayarınızın işlem gücüne bağlı olarak cidden uzun sürebilir. Eğer hemen sonuç almak istiyorsanız, eğitmeden önce modellerin bazılarını silin veya yorum satırına alın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_results = {}\n",
    "\n",
    "models_params = {\n",
    "    GaussianNB(): {},\n",
    "\n",
    "    tree.DecisionTreeClassifier(): {\n",
    "        'max_depth': list(range(1, 20)),\n",
    "        'max_features': list(range(1, feature_count + 1))\n",
    "    },\n",
    "    \n",
    "    MLPClassifier(): {\n",
    "        'activation': ['tanh', 'relu', 'logistic'],\n",
    "        'solver': ['sgd', 'adam'],\n",
    "        'alpha': [1e-4, 1e-3, 1e-2],\n",
    "        'max_iter': [200, 500, 1000]\n",
    "    },\n",
    "    \n",
    "    ensemble.RandomForestClassifier(): {\n",
    "        'n_estimators': [10, 100, 1000],\n",
    "        'max_depth': list(range(1, 20)),\n",
    "        'max_features': list(range(1, feature_count + 1))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada **models_params** adlı sözlüğün içindeki her bir eleman çifti için **GridSearchCV** kullanıyoruz. **n_jobs** parametresi ile paralelde kaç tane eğitim yapılabileceğini ayarlayabiliriz. Bunun genellikle işlemci çekirdek veya izlek sayısına eşit olması idealdir.\n",
    "\n",
    "Ardından her bir model için test skoru çıkartıp bunu **model_results** adlı sözlükte, anahtarı model olacak şekilde tutuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "for model, params in models_params.iteritems():\n",
    "    grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=4)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    test_score = grid.best_estimator_.score(X_test, y_test)\n",
    "    model_results[grid.best_estimator_] = test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test skoru en yüksek olan modeli doğrudan seçip kaydedebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=14,\n",
      "            max_features=14, max_leaf_nodes=None, min_impurity_split=1e-07,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "0.991066038875\n"
     ]
    }
   ],
   "source": [
    "best_model = max(model_results, key=model_results.get)\n",
    "\n",
    "print best_model\n",
    "print model_results[best_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeli kaydetmek için bu **pickle** kullanalım. **pickle** ve **cPickle** modülleri çoğu Python dağıtımında yüklü olarak gelmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/malware_detector.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeli tekrardan dosyadan yükleyip kullanmaya başlayabiliriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tahmin edilen sınıf: 0\n",
      "Confidence değerleri: [  9.99779978e-01   2.20022002e-04]\n"
     ]
    }
   ],
   "source": [
    "with open('data/malware_detector.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "sample = X_test[550, :].reshape(1, -1)\n",
    "\n",
    "print(u'Tahmin edilen sınıf: %d' % model.predict(sample)[0])\n",
    "print(u'Confidence değerleri: %s' % model.predict_proba(sample)[0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
